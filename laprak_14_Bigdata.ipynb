{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INM4-tRbw3ux"
      },
      "source": [
        "#Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le7VE5WVw_h9"
      },
      "source": [
        "##Introduction to Spark MLlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNnrMqPkwC-k",
        "outputId": "a9d61ec4-85da-4347-a595-959c49131661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0zqNPUyxB5v",
        "outputId": "2e5a7210-afe5-47c1-a879-d68485291bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+--------+--------+-------------+-----+\n",
            "| ID|Feature1|Feature2|FeatureVector|Label|\n",
            "+---+--------+--------+-------------+-----+\n",
            "|  1|     2.0|     3.0|    [2.0,3.0]|    0|\n",
            "|  2|     1.0|     5.0|    [1.0,5.0]|    1|\n",
            "|  3|     2.5|     4.5|    [2.5,4.5]|    1|\n",
            "|  4|     3.0|     6.0|    [3.0,6.0]|    0|\n",
            "+---+--------+--------+-------------+-----+\n",
            "\n",
            "Model Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Model Intercept: 11.56891272665312\n"
          ]
        }
      ],
      "source": [
        "# Practice: Logistic Regression\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Membuat SparkSession\n",
        "spark = SparkSession.builder.appName(\"LogisticRegressionModel\").getOrCreate()\n",
        "\n",
        "# Dataset contoh yang berisi ID, Fitur, dan Label\n",
        "data = [\n",
        "    (1, [2.0, 3.0], 0),\n",
        "    (2, [1.0, 5.0], 1),\n",
        "    (3, [2.5, 4.5], 1),\n",
        "    (4, [3.0, 6.0], 0)\n",
        "]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "\n",
        "# Mengubah data menjadi DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Menggunakan fungsi getItem() untuk mengekstrak elemen array menjadi kolom terpisah\n",
        "df = df.withColumn('Feature1', col('Features').getItem(0)) \\\n",
        "       .withColumn('Feature2', col('Features').getItem(1))\n",
        "\n",
        "# Menggunakan VectorAssembler untuk menggabungkan Feature1 dan Feature2 menjadi satu kolom vektor\n",
        "vector_assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='FeatureVector')\n",
        "df_transformed = vector_assembler.transform(df)\n",
        "\n",
        "# Menampilkan DataFrame setelah fitur digabungkan ke dalam vektor\n",
        "df_transformed.select('ID', 'Feature1', 'Feature2', 'FeatureVector', 'Label').show()\n",
        "\n",
        "# Membuat model regresi logistik dan melatihnya dengan data yang sudah diproses\n",
        "logistic_regression = LogisticRegression(featuresCol='FeatureVector', labelCol='Label')\n",
        "lr_model = logistic_regression.fit(df_transformed)\n",
        "\n",
        "# Menampilkan koefisien dan intercept dari model yang sudah dilatih\n",
        "print(f'Model Coefficients: {lr_model.coefficients}')\n",
        "print(f'Model Intercept: {lr_model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiE37TCfxSzR",
        "outputId": "4a40917e-1368-4662-ec0b-d5139cba4f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+--------+--------+-------------+\n",
            "| ID|Feature1|Feature2|FeatureVector|\n",
            "+---+--------+--------+-------------+\n",
            "|  1|     1.0|     1.0|    [1.0,1.0]|\n",
            "|  2|     5.0|     5.0|    [5.0,5.0]|\n",
            "|  3|    10.0|    10.0|  [10.0,10.0]|\n",
            "|  4|    15.0|    15.0|  [15.0,15.0]|\n",
            "+---+--------+--------+-------------+\n",
            "\n",
            "Cluster Centers: [array([12.5, 12.5]), array([3., 3.])]\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"KMeansClusteringExample\").getOrCreate()\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, [1.0, 1.0]), (2, [5.0, 5.0]), (3, [10.0, 10.0]), (4, [15.0, 15.0])]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Menggunakan fungsi getItem() untuk mengekstrak elemen array menjadi kolom terpisah\n",
        "df = df.withColumn('Feature1', col('Features').getItem(0)) \\\n",
        "       .withColumn('Feature2', col('Features').getItem(1))\n",
        "\n",
        "# Menggunakan VectorAssembler untuk menggabungkan Feature1 dan Feature2 menjadi satu kolom vektor\n",
        "vector_assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='FeatureVector')\n",
        "df_transformed = vector_assembler.transform(df)\n",
        "\n",
        "# Menampilkan DataFrame setelah fitur digabungkan ke dalam vektor\n",
        "df_transformed.select('ID', 'Feature1', 'Feature2', 'FeatureVector').show()\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='FeatureVector', k=2)\n",
        "model = kmeans.fit(df_transformed)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXF20WZoHeqB"
      },
      "source": [
        "# Praktikum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Dataset dan Handling data"
      ],
      "metadata": {
        "id": "b-Xmp5E6YH8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M4vEx6RuN15",
        "outputId": "928a4804-5b43-4ba9-b5a4-88697b1c310a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sebelum pembersihan:\n",
            "  COMPOUND  YEAR  STATE_CODE  COUNTY_CODE  LOW_ESTIMATE  HIGH_ESTIMATE\n",
            "0      24D  2014           1          1.0        1698.6         1885.5\n",
            "1      24D  2014           1          3.0        7513.6         8472.4\n",
            "2      24D  2014           1          5.0        2613.6         2889.4\n",
            "3      24D  2014           1          7.0        1259.2         1277.7\n",
            "4      24D  2014           1          9.0        7590.5         7756.1\n",
            "\n",
            "Dataset setelah pembersihan:\n",
            "  COMPOUND  YEAR  STATE_CODE  COUNTY_CODE  LOW_ESTIMATE  HIGH_ESTIMATE\n",
            "0      24D  2014           1          1.0        1698.6         1885.5\n",
            "1      24D  2014           1          3.0        7513.6         8472.4\n",
            "2      24D  2014           1          5.0        2613.6         2889.4\n",
            "3      24D  2014           1          7.0        1259.2         1277.7\n",
            "4      24D  2014           1          9.0        7590.5         7756.1\n",
            "\n",
            "Jumlah nilai yang hilang di setiap kolom:\n",
            "COMPOUND         0\n",
            "YEAR             0\n",
            "STATE_CODE       0\n",
            "COUNTY_CODE      0\n",
            "LOW_ESTIMATE     0\n",
            "HIGH_ESTIMATE    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-1bafc04a36bd>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['LOW_ESTIMATE'].fillna(mean_low_estimate, inplace=True)\n",
            "<ipython-input-1-1bafc04a36bd>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['HIGH_ESTIMATE'].fillna(median_high_estimate, inplace=True)\n",
            "<ipython-input-1-1bafc04a36bd>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['COUNTY_CODE'].fillna(median_county_code, inplace=True)\n",
            "<ipython-input-1-1bafc04a36bd>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['COMPOUND'].fillna('Unknown', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset yang telah dibersihkan disimpan ke 'pestisida_cleaned.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Membaca dataset\n",
        "file_path = 'pestisida.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Menampilkan informasi awal tentang dataset\n",
        "print(\"Dataset sebelum pembersihan:\")\n",
        "print(data.head())\n",
        "\n",
        "# Menghitung rata-rata dan median untuk pengisian data numerik\n",
        "mean_low_estimate = data['LOW_ESTIMATE'].mean()\n",
        "median_high_estimate = data['HIGH_ESTIMATE'].median()\n",
        "median_county_code = data['COUNTY_CODE'].median()\n",
        "\n",
        "# Mengisi data numerik yang hilang dengan mean atau median\n",
        "data['LOW_ESTIMATE'].fillna(mean_low_estimate, inplace=True)\n",
        "data['HIGH_ESTIMATE'].fillna(median_high_estimate, inplace=True)\n",
        "data['COUNTY_CODE'].fillna(median_county_code, inplace=True)\n",
        "\n",
        "# Mengisi data kategorikal yang hilang dengan 'Unknown'\n",
        "data['COMPOUND'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Menghapus baris yang memiliki nilai hilang pada kolom penting\n",
        "data.dropna(subset=['YEAR', 'STATE_CODE'], inplace=True)\n",
        "\n",
        "# Menghapus baris yang masih memiliki nilai hilang di kolom lain\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Memeriksa apakah ada nilai hilang setelah pembersihan\n",
        "print(\"\\nDataset setelah pembersihan:\")\n",
        "print(data.head())\n",
        "\n",
        "# Menampilkan jumlah nilai yang hilang di setiap kolom\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"\\nJumlah nilai yang hilang di setiap kolom:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Menyimpan dataset yang telah dibersihkan\n",
        "data.to_csv('pestisida_cleaned.csv', index=False)\n",
        "print(\"\\nDataset yang telah dibersihkan disimpan ke 'pestisida_cleaned.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Penggunaan Machine Learning"
      ],
      "metadata": {
        "id": "QgeI21LYYUTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Membuat sesi Spark\n",
        "spark = SparkSession.builder.appName(\"RandomForestClassification\").getOrCreate()\n",
        "\n",
        "# Membaca dataset\n",
        "file_path = 'pestisida_cleaned.csv'  # Ganti dengan path dataset Anda\n",
        "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Menampilkan informasi awal tentang dataset\n",
        "print(\"Dataset sebelum diproses:\")\n",
        "data.show(5)\n",
        "data.printSchema()\n",
        "\n",
        "# Preprocessing data\n",
        "# Mengonversi estimasi rendah dan tinggi menjadi kategori \"Tinggi\" atau \"Rendah\"\n",
        "data = data.withColumn(\n",
        "    \"usage_category\",\n",
        "    when((data['HIGH_ESTIMATE'] - data['LOW_ESTIMATE']) > 10000, 'Tinggi')  # Misalnya, penggunaan tinggi jika perbedaan estimasi > 10.000\n",
        "    .otherwise('Rendah')\n",
        ")\n",
        "\n",
        "# Menampilkan contoh data setelah menambahkan kategori penggunaan\n",
        "data.show(5)\n",
        "\n",
        "# Mengonversi label menjadi indeks numerik untuk klasifikasi\n",
        "label_column = 'usage_category'  # Kolom target baru\n",
        "feature_columns = ['STATE_CODE', 'COUNTY_CODE', 'LOW_ESTIMATE', 'HIGH_ESTIMATE']  # Kolom fitur\n",
        "\n",
        "# Mengonversi label menjadi indeks numerik\n",
        "indexer = StringIndexer(inputCol=label_column, outputCol='labelIndex')\n",
        "data = indexer.fit(data).transform(data)\n",
        "\n",
        "# Menggabungkan fitur menjadi satu vektor\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Membagi dataset menjadi data latih dan data uji\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Membuat model Random Forest\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='labelIndex', numTrees=100, seed=42)\n",
        "\n",
        "# Melatih model\n",
        "rf_model = rf.fit(train_data)\n",
        "\n",
        "# Mengevaluasi model pada data uji\n",
        "predictions = rf_model.transform(test_data)\n",
        "\n",
        "# Menggunakan evaluator untuk menghitung akurasi\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='labelIndex', predictionCol='prediction', metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "# Menampilkan hasil evaluasi\n",
        "print(f\"Akurasi pada data uji: {accuracy}\")\n",
        "\n",
        "# Menampilkan beberapa prediksi\n",
        "print(\"Beberapa prediksi:\")\n",
        "predictions.select('features', 'labelIndex', 'prediction', 'probability').show(10)\n",
        "\n",
        "# Menyimpan model\n",
        "rf_model.save(\"random_forest_model\")\n",
        "print(\"\\nModel Random Forest disimpan ke 'random_forest_model'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kefFTAqJMc2",
        "outputId": "6c9c7dd1-1d35-4000-b90d-30dd8f0abc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sebelum diproses:\n",
            "+--------+----+----------+-----------+------------+-------------+\n",
            "|COMPOUND|YEAR|STATE_CODE|COUNTY_CODE|LOW_ESTIMATE|HIGH_ESTIMATE|\n",
            "+--------+----+----------+-----------+------------+-------------+\n",
            "|     24D|2014|         1|        1.0|      1698.6|       1885.5|\n",
            "|     24D|2014|         1|        3.0|      7513.6|       8472.4|\n",
            "|     24D|2014|         1|        5.0|      2613.6|       2889.4|\n",
            "|     24D|2014|         1|        7.0|      1259.2|       1277.7|\n",
            "|     24D|2014|         1|        9.0|      7590.5|       7756.1|\n",
            "+--------+----+----------+-----------+------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- COMPOUND: string (nullable = true)\n",
            " |-- YEAR: integer (nullable = true)\n",
            " |-- STATE_CODE: integer (nullable = true)\n",
            " |-- COUNTY_CODE: double (nullable = true)\n",
            " |-- LOW_ESTIMATE: double (nullable = true)\n",
            " |-- HIGH_ESTIMATE: double (nullable = true)\n",
            "\n",
            "+--------+----+----------+-----------+------------+-------------+--------------+\n",
            "|COMPOUND|YEAR|STATE_CODE|COUNTY_CODE|LOW_ESTIMATE|HIGH_ESTIMATE|usage_category|\n",
            "+--------+----+----------+-----------+------------+-------------+--------------+\n",
            "|     24D|2014|         1|        1.0|      1698.6|       1885.5|        Rendah|\n",
            "|     24D|2014|         1|        3.0|      7513.6|       8472.4|        Rendah|\n",
            "|     24D|2014|         1|        5.0|      2613.6|       2889.4|        Rendah|\n",
            "|     24D|2014|         1|        7.0|      1259.2|       1277.7|        Rendah|\n",
            "|     24D|2014|         1|        9.0|      7590.5|       7756.1|        Rendah|\n",
            "+--------+----+----------+-----------+------------+-------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Akurasi pada data uji: 0.9999872692552514\n",
            "Beberapa prediksi:\n",
            "+--------------------+----------+----------+--------------------+\n",
            "|            features|labelIndex|prediction|         probability|\n",
            "+--------------------+----------+----------+--------------------+\n",
            "|[1.0,5.0,2613.6,2...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,13.0,2798.2,...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,17.0,4784.1,...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,27.0,4097.6,...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,39.0,2676.7,...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,47.0,3606.8,...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,59.0,11344.8...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,71.0,9396.4,...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,91.0,1978.5,...|       0.0|       0.0|[0.99999748330964...|\n",
            "|[1.0,93.0,6626.1,...|       0.0|       0.0|[0.99999748330964...|\n",
            "+--------------------+----------+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "Model Random Forest disimpan ke 'random_forest_model'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter"
      ],
      "metadata": {
        "id": "8Ll0g_SRYcHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Membuat sesi Spark\n",
        "spark = SparkSession.builder.appName(\"RandomForestClassificationWithHyperparameterTuning\").getOrCreate()\n",
        "\n",
        "# Membaca dataset\n",
        "file_path = 'pestisida_cleaned.csv'  # Ganti dengan path dataset Anda\n",
        "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Menampilkan informasi awal tentang dataset\n",
        "print(\"Dataset sebelum diproses:\")\n",
        "data.show(5)\n",
        "data.printSchema()\n",
        "\n",
        "# Preprocessing data\n",
        "# Mengonversi estimasi rendah dan tinggi menjadi kategori \"Tinggi\" atau \"Rendah\"\n",
        "data = data.withColumn(\n",
        "    \"usage_category\",\n",
        "    when((data['HIGH_ESTIMATE'] - data['LOW_ESTIMATE']) > 10000, 'Tinggi')\n",
        "    .otherwise('Rendah')\n",
        ")\n",
        "\n",
        "# Menampilkan contoh data setelah menambahkan kategori penggunaan\n",
        "data.show(5)\n",
        "\n",
        "# Mengonversi label menjadi indeks numerik untuk klasifikasi\n",
        "label_column = 'usage_category'  # Kolom target baru\n",
        "feature_columns = ['STATE_CODE', 'COUNTY_CODE', 'LOW_ESTIMATE', 'HIGH_ESTIMATE']  # Kolom fitur\n",
        "\n",
        "# Mengonversi label menjadi indeks numerik\n",
        "indexer = StringIndexer(inputCol=label_column, outputCol='labelIndex')\n",
        "data = indexer.fit(data).transform(data)\n",
        "\n",
        "# Menggabungkan fitur menjadi satu vektor\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Membagi dataset menjadi data latih dan data uji\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Membuat model Random Forest\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='labelIndex', seed=42)\n",
        "\n",
        "# Membuat grid parameter untuk tuning\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(rf.numTrees, [50, 100, 150]) \\\n",
        "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
        "    .addGrid(rf.maxBins, [32, 64]) \\\n",
        "    .build()\n",
        "\n",
        "# Membuat evaluator untuk menghitung akurasi\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='labelIndex', predictionCol='prediction', metricName='accuracy')\n",
        "\n",
        "# Membuat CrossValidator\n",
        "cross_validator = CrossValidator(\n",
        "    estimator=rf,\n",
        "    estimatorParamMaps=param_grid,\n",
        "    evaluator=evaluator,\n",
        "    numFolds=5,  # Jumlah lipatan k-fold cross-validation\n",
        "    parallelism=2  # Menjalankan proses secara paralel\n",
        ")\n",
        "\n",
        "# Melatih model dengan cross-validation\n",
        "cv_model = cross_validator.fit(train_data)\n",
        "\n",
        "# Mengevaluasi model terbaik pada data uji\n",
        "predictions = cv_model.transform(test_data)\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "# Menampilkan hasil evaluasi\n",
        "print(f\"Akurasi terbaik pada data uji: {accuracy}\")\n",
        "\n",
        "# Menampilkan beberapa prediksi\n",
        "print(\"Beberapa prediksi:\")\n",
        "predictions.select('features', 'labelIndex', 'prediction', 'probability').show(10)\n",
        "\n",
        "# Menyimpan model terbaik\n",
        "cv_model.bestModel.save(\"best_random_forest_model\")\n",
        "print(\"\\nModel Random Forest terbaik disimpan ke 'best_random_forest_model'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuuTmpVQKjUu",
        "outputId": "a9616f42-3d8a-4f22-abbf-e93011f933d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sebelum diproses:\n",
            "+--------+----+----------+-----------+------------+-------------+\n",
            "|COMPOUND|YEAR|STATE_CODE|COUNTY_CODE|LOW_ESTIMATE|HIGH_ESTIMATE|\n",
            "+--------+----+----------+-----------+------------+-------------+\n",
            "|     24D|2014|         1|        1.0|      1698.6|       1885.5|\n",
            "|     24D|2014|         1|        3.0|      7513.6|       8472.4|\n",
            "|     24D|2014|         1|        5.0|      2613.6|       2889.4|\n",
            "|     24D|2014|         1|        7.0|      1259.2|       1277.7|\n",
            "|     24D|2014|         1|        9.0|      7590.5|       7756.1|\n",
            "+--------+----+----------+-----------+------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- COMPOUND: string (nullable = true)\n",
            " |-- YEAR: integer (nullable = true)\n",
            " |-- STATE_CODE: integer (nullable = true)\n",
            " |-- COUNTY_CODE: double (nullable = true)\n",
            " |-- LOW_ESTIMATE: double (nullable = true)\n",
            " |-- HIGH_ESTIMATE: double (nullable = true)\n",
            "\n",
            "+--------+----+----------+-----------+------------+-------------+--------------+\n",
            "|COMPOUND|YEAR|STATE_CODE|COUNTY_CODE|LOW_ESTIMATE|HIGH_ESTIMATE|usage_category|\n",
            "+--------+----+----------+-----------+------------+-------------+--------------+\n",
            "|     24D|2014|         1|        1.0|      1698.6|       1885.5|        Rendah|\n",
            "|     24D|2014|         1|        3.0|      7513.6|       8472.4|        Rendah|\n",
            "|     24D|2014|         1|        5.0|      2613.6|       2889.4|        Rendah|\n",
            "|     24D|2014|         1|        7.0|      1259.2|       1277.7|        Rendah|\n",
            "|     24D|2014|         1|        9.0|      7590.5|       7756.1|        Rendah|\n",
            "+--------+----+----------+-----------+------------+-------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Akurasi terbaik pada data uji: 0.9999872692552514\n",
            "Beberapa prediksi:\n",
            "+--------------------+----------+----------+--------------------+\n",
            "|            features|labelIndex|prediction|         probability|\n",
            "+--------------------+----------+----------+--------------------+\n",
            "|[1.0,5.0,2613.6,2...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,13.0,2798.2,...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,17.0,4784.1,...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,27.0,4097.6,...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,39.0,2676.7,...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,47.0,3606.8,...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,59.0,11344.8...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,71.0,9396.4,...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,91.0,1978.5,...|       0.0|       0.0|[0.99999757964598...|\n",
            "|[1.0,93.0,6626.1,...|       0.0|       0.0|[0.99999757964598...|\n",
            "+--------------------+----------+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "Model Random Forest terbaik disimpan ke 'best_random_forest_model'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nhH5XP4WfMNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "INM4-tRbw3ux",
        "b-Xmp5E6YH8b",
        "QgeI21LYYUTH",
        "8Ll0g_SRYcHY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}