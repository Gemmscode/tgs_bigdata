{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13116094-e06f-4db1-82be-55a0060ec6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e61d708-4b65-47e5-952e-a0af747b3f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\najmi mukia barkah\\anaconda3\\envs\\praktikum_bigdata_gema\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0802d833-71e6-47f8-b041-b4c65e9f9274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|       James|     Sales|  3000|\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|     Sales|  4100|\n",
      "|       Maria|   Finance|  3000|\n",
      "+------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Contoh membuat DataFrame sederhana dan operasi dasar\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('HandsOnPertemuan6').getOrCreate()\n",
    "\n",
    "data = [('James', 'Sales', 3000),\n",
    "        ('Michael', 'Sales', 4600),\n",
    "        ('Robert', 'Sales', 4100),\n",
    "        ('Maria', 'Finance', 3000)]\n",
    "columns = ['EmployeeName', 'Department', 'Salary']\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f07159-906e-498c-aa38-09a23d7ceb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Tabel Pegawai dan Salary\n",
      "+------------+------+\n",
      "|EmployeeName|Salary|\n",
      "+------------+------+\n",
      "|       James|  3000|\n",
      "|     Michael|  4600|\n",
      "|      Robert|  4100|\n",
      "|       Maria|  3000|\n",
      "+------------+------+\n",
      "\n",
      "Data Pegawai dengan Salary lebih dari 3000\n",
      "+------------+----------+------+\n",
      "|EmployeeName|Department|Salary|\n",
      "+------------+----------+------+\n",
      "|     Michael|     Sales|  4600|\n",
      "|      Robert|     Sales|  4100|\n",
      "+------------+----------+------+\n",
      "\n",
      "Rata=rata Salary Untuk Tiap Departement\n",
      "+----------+-----------+\n",
      "|Department|avg(Salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|     3900.0|\n",
      "|   Finance|     3000.0|\n",
      "+----------+-----------+\n",
      "\n",
      "Insight Dataset\n",
      "+----------+----------------+-----------------+---------------+------------+\n",
      "|Department|Rata-rata salary|Salarry Tertinggi|Salary Terendah|Total Salary|\n",
      "+----------+----------------+-----------------+---------------+------------+\n",
      "|     Sales|          3900.0|             4600|           3000|       11700|\n",
      "|   Finance|          3000.0|             3000|           3000|        3000|\n",
      "+----------+----------------+-----------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh operasi transformasi DataFrame\n",
    "from pyspark.sql.functions import mean, max, sum, min\n",
    "\n",
    "print (\"Data Tabel Pegawai dan Salary\")\n",
    "df_select = df.select('EmployeeName', 'Salary')\n",
    "df_select.show()\n",
    "\n",
    "# Melakukan filter untuk menampilkan data dengan salary > 3000\n",
    "print(\"Data Pegawai dengan Salary lebih dari 3000\")\n",
    "df_filter = df.filter(df['Salary'] > 3000)\n",
    "df_filter.show()\n",
    "\n",
    "# Menghitung rata-rata dari data salary untuk tiap departemen\n",
    "print(\"Rata=rata Salary Untuk Tiap Departement\")\n",
    "df_groupBy = df.groupBy('Department').avg('Salary')\n",
    "df_groupBy.show()\n",
    "\n",
    "print(\"Insight Dataset\")\n",
    "ringkasan_df = df.groupBy('Department').agg(\n",
    "    mean(\"Salary\").alias(\"Rata-rata salary\"),\n",
    "    max(\"Salary\").alias(\"Salarry Tertinggi\"),\n",
    "    min(\"Salary\").alias(\"Salary Terendah\"),\n",
    "    sum(\"Salary\").alias(\"Total Salary\")\n",
    ")\n",
    "ringkasan_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1892bf5-1539-47cb-8e08-3ec5d55b929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+-----------+-----------------+\n",
      "|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "|       James|     Sales|  3000|      300.0|           3300.0|\n",
      "|     Michael|     Sales|  4600|      460.0|           5060.0|\n",
      "|      Robert|     Sales|  4100|      410.0|           4510.0|\n",
      "|       Maria|   Finance|  3000|      300.0|           3300.0|\n",
      "+------------+----------+------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh manipulasi tipe data kompleks\n",
    "\n",
    "df = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n",
    "df = df.withColumn('TotalCompensation', df['Salary'] + df['SalaryBonus'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e3acf1-1f74-406c-82ee-3d1a4be5e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------+----+\n",
      "|EmployeeName|Department|Salary|Rank|\n",
      "+------------+----------+------+----+\n",
      "|       Maria|   Finance|  3000|   1|\n",
      "|       James|     Sales|  3000|   1|\n",
      "|      Robert|     Sales|  4100|   2|\n",
      "|     Michael|     Sales|  4600|   3|\n",
      "+------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Contoh menggunakan window functions\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "windowSpec = Window.partitionBy('Department').orderBy('Salary')\n",
    "df.withColumn('Rank', F.rank().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efaacad8-d741-4385-91a7-cfa5fa5bbb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------+--------------+---------------+--------------------------+-----------+--------+---------+--------+------+---------+----+\n",
      "|Age|Gender|Marital Status|    Occupation| Monthly Income|Educational Qualifications|Family size|latitude|longitude|Pin code|Output| Feedback|_c12|\n",
      "+---+------+--------------+--------------+---------------+--------------------------+-----------+--------+---------+--------+------+---------+----+\n",
      "| 20|Female|        Single|       Student|      No Income|             Post Graduate|          4| 12.9766|  77.5993|  560001|   Yes| Positive| Yes|\n",
      "| 24|Female|        Single|       Student| Below Rs.10000|                  Graduate|          3|  12.977|  77.5773|  560009|   Yes| Positive| Yes|\n",
      "| 22|  Male|        Single|       Student| Below Rs.10000|             Post Graduate|          3| 12.9551|  77.6593|  560017|   Yes|Negative | Yes|\n",
      "| 22|Female|        Single|       Student|      No Income|                  Graduate|          6| 12.9473|  77.5616|  560019|   Yes| Positive| Yes|\n",
      "| 22|  Male|        Single|       Student| Below Rs.10000|             Post Graduate|          4|  12.985|  77.5533|  560010|   Yes| Positive| Yes|\n",
      "| 27|Female|       Married|      Employee|More than 50000|             Post Graduate|          2| 12.9299|  77.6848|  560103|   Yes| Positive| Yes|\n",
      "| 22|  Male|        Single|       Student|      No Income|                  Graduate|          3|  12.977|  77.5773|  560009|   Yes| Positive| Yes|\n",
      "| 24|Female|        Single|       Student|      No Income|             Post Graduate|          3| 12.9828|  77.6131|  560042|   Yes| Positive| Yes|\n",
      "| 23|Female|        Single|       Student|      No Income|             Post Graduate|          2| 12.9766|  77.5993|  560001|   Yes| Positive| Yes|\n",
      "| 23|Female|        Single|       Student|      No Income|             Post Graduate|          4| 12.9854|  77.7081|  560048|   Yes| Positive| Yes|\n",
      "| 22|Female|        Single|       Student|      No Income|             Post Graduate|          5|  12.985|  77.5533|  560010|   Yes| Positive| Yes|\n",
      "| 23|  Male|        Single|       Student| Below Rs.10000|             Post Graduate|          2|  12.977|  77.5773|  560009|   Yes|Negative | Yes|\n",
      "| 23|  Male|        Single|       Student|      No Income|             Post Graduate|          5| 12.8988|  77.5764|  560078|   Yes| Positive| Yes|\n",
      "| 21|  Male|        Single|       Student|      No Income|                  Graduate|          4|  12.977|  77.5773|  560009|   Yes| Positive| Yes|\n",
      "| 23|Female|        Single|Self Employeed| 10001 to 25000|             Post Graduate|          5| 12.9438|  77.5738|  560004|   Yes| Positive| Yes|\n",
      "| 24|Female|        Single|       Student|      No Income|             Post Graduate|          6| 12.8893|  77.6399|  560068|   Yes| Positive| Yes|\n",
      "| 28|Female|        Single|      Employee| 25001 to 50000|             Post Graduate|          2| 12.9783|  77.6408|  560038|   Yes| Positive| Yes|\n",
      "| 23|Female|        Single|       Student|      No Income|                  Graduate|          3|  12.982|  77.6256|  560008|   Yes|Negative | Yes|\n",
      "| 25|  Male|        Single|       Student|      No Income|                  Graduate|          4| 12.8988|  77.5764|  560078|   Yes|Negative | Yes|\n",
      "| 21|Female|        Single|       Student| Below Rs.10000|             Post Graduate|          1| 12.9783|  77.6408|  560038|   Yes| Positive| Yes|\n",
      "+---+------+--------------+--------------+---------------+--------------------------+-----------+--------+---------+--------+------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Datakaggle\").getOrCreate()\n",
    "\n",
    "# Untuk membaca file\n",
    "file_path = \"/C:/Users/Najmi Mukia Barkah/Documents/onlinefoods.csv\"\n",
    "df = spark.read.csv(file_path, header = True, inferSchema = True)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91862a90-3090-42b1-8045-5b6f91e8255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Marital Status: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- Monthly Income: string (nullable = true)\n",
      " |-- Educational Qualifications: string (nullable = true)\n",
      " |-- Family size: integer (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- Pin code: integer (nullable = true)\n",
      " |-- Output: string (nullable = true)\n",
      " |-- Feedback: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0da5dd2-0cb5-4ef9-9bdf-68885b82ac6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+\n",
      "|   Marital Status|  Female|    Male|\n",
      "+-----------------+--------+--------+\n",
      "|Prefer not to say| 2800091| 3920444|\n",
      "|          Married|27441934|33042912|\n",
      "|           Single|62724419|87365764|\n",
      "+-----------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Marital Status\").pivot(\"Gender\").sum(\"Pin code\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef030d-38a9-4de0-8238-16fcbd4b4a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
